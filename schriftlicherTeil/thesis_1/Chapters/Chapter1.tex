
\chapter{Introduction} 

\label{Chapter1} 

\section{Software Transactional Memory}
\label{STMInterface}
Software Transactional Memory (STM in the following) is a programming language independent synchronization concept. Today STM is available 
in all common programming languages\footnote{Even though STM is language independent, I will present the STM library in Haskell since this thesis is
about STM in Haskell}. To understand the benefits of STM, take a look at the following example:
\begin{lstlisting}
type Account = MVar Int

transfer :: Account -> Account -> Int -> IO ()
transfer src dst am = do
  balSrc <- takeMVar src
  balDst <- takeMVar dst
  putMVar src (balSrc - am)
  putMVar dst (balDst + am)
\end{lstlisting}
This is a simple implementation of a bank account and an associated transfer function. This implementation uses an \code{MVar}
for synchronization. An \code{MVar} is a buffer with a capacity of one. This buffer can either be empty or filled. If the MVar is empty,
every \code{takeMVar} operation on this MVar blocks until it is filled. If the MVar is filled, \code{takeMVar} empties the 
\code{MVar} and return the value. \code{putMVar} is the opposite operation. It fills the MVar with a value, if it is empty and 
suspends if the MVar is already filled.

This means \code{transfer} first empties both \code{Accounts}, then modifies the balances and at last writes back the new balances.
At first glance this function seems to work fine, but the following example contains a deadlock:
\par\noindent
\begin{minipage}[t]{.45\textwidth}
Thread 1:
\begin{lstlisting}[frame=lrtb]
main = do
  transfer acc1 acc2 50
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
Thread 2:
\begin{lstlisting}[frame=lrtb]
main = do
  transfer acc2 acc1 50
\end{lstlisting}
\end{minipage}

The problem is the mutual access of the MVars. If both threads take their \code{src} at the same time, they will both wait for \code{dst}
\footnote{In fact is \code{transfer acc1 acc1 50} enough to evoke a deadlock}. To avoid this deadlock we can rewrite the code:
\begin{lstlisting}
transfer src dst am = do
  srcBal <- takeMVar src
  putMVar src (srcBal - am)
  dstBal <- takeMVar dst
  putMVar dst (dstBal + am)
\end{lstlisting}
This indeed solves the problem regarding the deadlock. In return we lose consistency. For a brief moment we see an inconsistent state. Since
the amount is allready subtracted from one account, but not yet added to the other account. This inconsistent state is observable by other 
threads. This is not possible in the first implementation. 

We can use STM to avoid these problems. STM provides a single element buffer named \code{TVar}. A TVar always holds an value and is never 
empty. TVars are read and written with the functions \code{readTVar} and \code{writeTVar}, respectively. 
In contrast to \code{putMVar} and \code{takeMVar}, the TVar operations are not \code{IO} actions but \code{STM} action\footnote{If 
you are wondering when I use \code{SMT} and when STM. I use \code{STM} when I refer to the Haskell type constructor and STM when I refer to STM as library}. 
\code{STM} is an instance of Monad, hence multiple \code{STM} actions can be combined
using the comfortable do-notation. The following code represents the example from above implemented with TVars instead of MVars:
\begin{lstlisting}
type Account = TVar Int

transfer :: Account -> Account -> Int -> STM ()
transfer src dst am = do
  srcBal <- readTVar src
  dstBal <- readTVar dst
  writeTVar src (srcBal - am)
  writeTVar dst (dstBal + am)
\end{lstlisting}
Note the type of transfer is no longer an \code{IO} action, but an \code{STM} action. Apart from this the code looks
similar to the MVar version.

In order to execute a transaction the function \code{atomically :: STM a -> IO a} is used. 
Since \code{readTVar} and \code{writeTVar} do not lock the TVar, the following example contains no deadlock:
\par\noindent
\begin{minipage}[t]{.45\textwidth}
Thread 1:
\begin{lstlisting}[frame=lrtb]
main = do
  atomically $
    transfer acc1 acc2 50
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
Thread 2:
\begin{lstlisting}[frame=lrtb]
main = do 
  atomically $ 
    transfer acc2 acc1 50
\end{lstlisting}
\end{minipage}

This is because STM ensures the \keyword{ACID} properties. The ACID properties were Introduced in \parencite{DBTrans} for
database transactions. These properties were adapted for software transactions later on.
In the case of software transactions the ACID properties mean the following:
\begin{itemize}
 \item \keyword{Atomicity}: the transaction executes all operations or none.
 \item \keyword{Consistency}: all modifications of a transaction are committed at the same time. No transition state is observable.
 \item \keyword{Isolation}: no concurrency is observable by a transaction. Each transaction can work as if it is the only transaction.
 \item \keyword{Durability}: ensures the perseverance of the changes. In the case of software transactions this is not necessary.
\end{itemize}
These properties explain the name \code{atomically}, because the enclosed code appears to be executed instantaneously without any 
interactions with other threads.
Before we turn over to the implementation of STM, we take a deeper look at the interface of the STM.

\code{newTVar :: a -> STM (TVar a)} creates a newTVar. Since a TVar always holds a value, an initial value has to be
passed to create a TVar. There is no function like \code{newEmptyTVar}. 

Besides functions to create and access TVars, there are functions to alter the control flow.
\code{retry :: STM a} is a generic STM action that indicates a failure, thus whenever a transaction engages a \code{retry} it restarts. The transaction
is \textbf{not} restarted immediately. The transaction restarts, if at least one of the TVars it has read is modified. If the transaction would
restart immediately (and no TVar has changed), the transaction would run into the same \code{retry} again. 

With \code{orElse :: STM a $\rightarrow$ STM a $\rightarrow$ STM a} you are able to express alternatives. \code{orElse} executes the first transaction
and ignores the second transaction, if the first transaction is successful. If the first transaction fails (retries), the second transaction is 
executed instead.

Note that it is not possible to execute \code{IO} action within a transaction, which means that not side effects can occur. Furthermore this means
restarting a transaction will never lead to the re-execution of irreversible operations. The reason is that the computations of transactions
are done within the \code{STM} Monad. In other words the type system of Haskell forces us to write correct transactions. 

For single threaded programming, abstraction and composability are key features. These features allow us to combine smaller pieces
of code into more complex pieces of code. These feature are not available for lock based concurrent programming. Compose correct lock based
concurrent functions most likely lead to deadlocks or inconsistencies. Consider the following example:
\begin{lstlisting}
withdraw :: Account -> Int -> IO()
withdraw acc am = do 
  bal <- takeMVar acc 
  putMVar acc (bal - am)
 
deposit :: Account -> Int -> IO()
deposit acc am = withdraw acc (-am)
\end{lstlisting}
These are functions to withdraw and deposit money from and on an account. The natural way to implement \code{transfer} is:
\begin{lstlisting}
transfer :: Account -> Account -> Int -> IO()
transfer src dst am = do
  withdraw src am
  deposit dst am
\end{lstlisting}
We reuse the functions that are already defined instead of coding everything from the scratch. In our example this is equivalent 
to the solution suggested above to eliminate the deadlock. This implementation is free of deadlocks, but it lacks consistency.
Thus building complex concurrent operations can not take advantage of abstraction and composability. We always need to code
everything from the scratch. This is error prone in compared to the step wise combination of smaller operations into 
bigger operations.

STM allows us to use this important programming paradigm for concurrent programming. Thus the following example provides
deadlock freedom as well as consistency.
\begin{lstlisting}
withdraw :: Account -> Int -> STM()
withdraw acc am = do 
  bal <- readTVar acc 
  writeTVar acc (bal - am)
 
deposit :: Account -> Int -> STM()
deposit acc am = withdraw acc (-am)

transfer :: Account -> Account -> Int -> STM()
transfer src dst am = do
  withdraw src am
  deposit dst am
\end{lstlisting}
We can combine arbitrary transactions to more complex transactions while preserving the ACI properties. This greatly benefits the 
readability of the code. In addition it increases the efficiency of the development process, because we are able to reuse code
that we already found to be correct. This was also one of the main motivations of paper \parencite{STMBase} which forms the foundation
of STM in Haskell.

  
\section{Implementation}
In this we explore the current implementation of STM in Haskell, more specific in GHC. For a detailed description of the implementation 
refer to \url{https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/STM}. 

Even though the current implementation uses a low level C-library, we retain an abstract view on the implementation, since the technical 
details are not important for the course of this thesis. An abstract view on the implementation is presented to understand how the ACI 
properties are ensured.

The execution of a transaction (a call of \code{atomically}) is split in two phases. First the computation phase and second the commit phase. 
 
\subsection{Computation Phase}
Each transaction holds a log for the TVars it has accessed. The log contains four elements per entry. These are: 
\begin{itemize}
 \item tvar
 \item expectedValue
 \item newValue
 \item versionNumber
\end{itemize}
The \code{versionNumber} is only used to prevent a very subtle bug and thus not considered in this thesis. 
The log is extenden and modified by the transactional operations \code{writeTVar} and \code{readTVar}. \code{newTVar} on 
the other hand creates the new TVar directly. Whenever \code{readTVar} is called the associated TVar is lookep up in the log.
If it is present, the \code{newValue} is returned. If it is not present, a new entry for the log is created. While \code{tvar}
is the passed TVar, \code{newValue} and \code{expectedValue} are the actual value of the TVar and \code{versionNumber} is 
the actual verison number.
This is the one of the two times in the computation phase when the transaction accesses the actual mutable data structures.  
After the entry is created and added to the log, the actual value is returned. 

A call of \code{writeTVar} also looks up the associated TVar in the log. If it is present, the field \code{newValue} is 
set to the value passed to writeTVar. If it is not present, a new entry is created. The \code{tvar} is the passed TVar and
the \code{newValue} is the passed value and \code{expectedValue} is the actual value of that TVar. This is the other time 
the actual mutable data structures are accessed in the computation phase. 

This log fulfills two purposes. One purpose of the log is the use in the commit phase which is described in \ref{Sec:STMImpl}.
The other is the interaction between \code{readTVar} and \code{writeTVar}. The \code{readTVar} operations are able to see the results 
of preceding \code{writeTVar} operations in the log. Without the log \code{writeTVar} would need to access the actual TVar. This on the 
other hand would imply that other transactions would be able to see inconsistent intermediate states of the system;
a violation of the ACI properties. It may seem unnecessary to read a TVar that the transaction itself wrote before.
The transaction should know what it writes and thus does not need to access such TVars. Nevertheless there are two reasons 
to allow it. The current implementation allow the user to combine all transactional actions in an arbitrary manner and 
the library ensures (at compile time) that it works correctly. To restrict the user to only read TVars he has
not yet written, no longer allows the library to give this kind of guarantee at compile time; this contradicts
the design concept of Haskell. The second reason is one of the core motivations of STM in Haskell: composability.
With the restriction it is not possible to combine arbitrary correct STM functions to new more complex STM
functions. 

Take a look at the following example:
\begin{lstlisting}
transaction = do
  a <- readTVar t1
  b <- readTVar t2
  writeTVar t1 b
  writeTVar t2 a
\end{lstlisting}
This code would lead to the following log:
\begin{lstlisting}
 log  = {(t1,a,b),(t2,b,a)}
\end{lstlisting}
The log contains two entries, because the transaction accessed two TVars. The first entry contains the information that \code{t1}
hold the value \code{a} when it was first read and the value \code{b} is the new value of it. \code{t2} hold the value \code{b} 
and the new value is \code{a}. Before we will examine the commit phase, we will look at the other operations of the STM interface.

\code{newTVar} creates a new TVar and initializes this TVar. Afterwards this TVar can be used like already existing TVars.
Even if the transaction is rolled back, the new created TVars are not deleted explicitly. This work is done by the garbage
collector, since the TVars are not further referenced, if the transaction that created them is rolled back. 

\code{retry} aborts the computation and returns a results that indicates a failure. This result may be intercepted by 
\code{orElse} or is passed to \code{atomically} directly. 

If \code{atomically} receives an result that indicates an failure, it aborts the transactions. 
Aborting a transaction means to discard the log. Since no observable operations are performed in the computation phase, nothing has to be undone. 
As soon as at least one of the TVars in the log has changed, the transaction is restarted. If the transaction is restarted immediately and no 
TVar has changed the transaction would reach the same \code{retry} again. These changes can be checked by comparing the \code{expectedValue} in
the log with the actual value in the TVar. To avoid busy waiting the thread do not repeatedly check if the value has changed. The TVar has a 
queue for wait waiting threads. Each time a transaction successfully commits and writes a TVar it also checks if there is someone waiting in 
this queue. The committing thread then notifies all waiting threads.

\code{orElse} on the other hand reacts differently on the the result that indicates a failure. The implementation works with nested transactions, 
but to explain this in detail would go beyond the scope of this thesis. Nested transactions are not able to publish their writes on their own.
When a nested transaction successfully commits(we see in the next section what this means), its log is integrated in the log of the surrounding transaction. 
Integrated means the logs are merged and in the case one entry is in both log the entry of the outer transaction is discarded.
If the nested transaction fails, because \code{retry} occurred and it is the first transaction of \code{orElse}, the log of the inner transaction
is integrated in the log of the surrounding transaction, but the \code{newValue} fields of the inner log are ignored. If the nested transaction
fails to validate the outermost transaction is rolled back.

In conclusion the interface functions of STM are processed in the computation phase as follows:
\begin{itemize}
 \item \code{writeTVar}: Look up TVar in log. If present update \code{newValue}. If not present read actual TVar and create new entry.
 \item \code{readTVar}: Look up TVar in log. If present return \code{newValue}. If not present read actual TVar and create new entry.
 \item \code{newTVar}: Create and initialize a new TVar. 
 \item \code{retry}: Return a result that indicates a failure.
 \item \code{orElse}: Create a nested Transaction and reacts on the return value of that transaction.
\end{itemize}

\subsection{Commit Phase}
\label{Sec:STMImpl}
After the log is calculated and no further STM actions need to be processed, the commit phase starts.
At first the transaction validates if the values in its log are still correct by \keyword{validating} its log.
Validation denotes the process to check if the expectedValues are equal to the actual values in the TVars.
In other words for each entry in the log the transaction reads the actual TVar and compares the value with 
the \code{expectedValue} in the log. If at least one of these values does not match, the transaction is considered
\keyword{invalid}. If the validation returns the transaction is instantaneously rolled back, by discarding the log 
and restart it computation. If all values match the the transaction is considered \keyword{valid}. If the validation
returns valid, each entry in the log is processed. 

If \code{expectedValue} differs from \code{newValue} the associated TVar is locked. The transaction has acquired all 
locks it needs, it validates again. This seems a bit wasteful in terms of resources, but locking the TVars is considered
an expensive operation and thus the implementation tries to avoid this when ever possible. This process reduces the chance
that the transaction acquires all locks and then finds out it is invalid and consequently a unnecessary locking of TVars.
If the validation fails at this point, the transaction is rolled back after the locks has been released.
If the transaction has acquired all locks and is valid the transaction is is ready to publish its changes.
This means iterating on the log and update the actual TVars where \code{expectedValue} and \code{newValue} differ and
simultaneously releasing the locks. 

If the validation returns invalid it means at least one \code{expectedValue} is no longer correct. To roll back is essential 
to retain the ACI properties. The failed validation indicates that transaction has read an outdated value and possibly worked 
with this value. Take a look at the following example:
\begin{lstlisting}
transaction = do 
  a <- readTVar t1
  writeTVar t1 (a+1)
\end{lstlisting}
If this transaction is processed by two transactions in parallel. Both would read the initial value of \code{t1}, say \code{1}.
So both would note in their log \code{(t1,1,1)}. After the \code{writeTVar} the log of both transactions would look contain 
\code{(t1,1,2)}. After that both transactions try to commit. Assume one transaction commits before the other transaction tries.
\footnote{For simplicity we assume that no other transaction is running besides the two we are looking at.}
Then the transaction would find its log to be valid and lock \code{t1}. After that its log is still valid and so it modifies 
\code{t1} and releases the log. 
Then the second transaction tries to commit. Since the actual value hast changed to \code{2} it does no longer match 
the \code{expectedValue} and the transaction is rolled back. If the transaction would not be rolled back at this point
and commit instead. The transaction would write \code{2} to the TVar (that already contains \code{2}). In the end 
this would means the value of \code{t1} is \code{2} after both transactions have finished. This is certainly not the 
intended behaviour after incrementing the TVar that holds \code{1} twice. This is the well known \keyword{lost update}
problem. 

By rolling back the second transaction it reads \code{t1} once more. The log contains \code{(t1,2,2)} after the \code{readTVar}
operation and \code{(t1,2,3)} after the \code{writeTVar} operation. Then the transaction validates, locks, validates and 
finally publishes it modifications. In the end the value of \code{t1} is \code{3}; just as intended.

\subsection{Notes on the Implementation}
Larus and Rajwar describe in their book\parencite[Chapter 2]{transBook} different design options to be done when implementing a 
(Software) Transactional Memory. While most of these options effect the performance of a system, some also effect the 
semantics of the system. I will now discuss the design options that are important for this thesis \footnote{The names used in the 
following part are taken from \parencite[Chapter 2]{transBook}}.

\subsubsection{Deferred and Direct Updates} The way a STM system modifies the underlying data structure can either be \keyword{deferred}
or \keyword{direct}. Direct updating systems are writing the actual objects when a write operation is called. In the case of Haskell 
this would mean, every time \code{writeTVar} is called. Deferred updating systems on the other hand buffer the write operations to
commit them later on. Haskell STM is a deferred updating system, since the values are buffered in the writeSet before they are
committed. This design options does not effect the semantics of the system. While a direct system loses performance, when transaction
is rolled back, because the initial values need to be restored, a deferred systems contains an overhead due to the writeSet and the 
need to look up values in it when an Object is read. Neither mechanism is better than the other; it depends on the application STM 
is used in. \parencite{pessimisticSTM} compares a deferred and a direct system. They show that the performance of a direct update 
system is significantly higher than that of a deferred system, when reads outnumber writes by far.

\subsubsection{Early and Late Conflict Detection} A STM system needs to detect conflicts in order to ensure the ACI properties. This can 
be done as soon as the conflict occurs or at some point later before the transaction commits. If the system uses a late conflict 
detection, transaction may work on an inconsistent state. This may leads to loops or exceptions. So this a semantic relevant design 
decision. Haskell STM uses a late conflict detection. By validating the readSet before comitting the transaction a possible conflict
is detected. This implies the transaction may work on an inconsistent state until it attempts to commit. This means the transaction 
may run into an infinite loop, because it saw an inconsistent state. To avoid this problem, additional validations are performed
each time the executing thread yields. Exceptions raised by the transaction are handled like a \code{retry}. If the readSet is valid,
the transcation waits until at leas on TVar it has read is changed. If it is invalid the transaction is restarted immediately.
In conclusion, the user of STM can not observe that the transaction worked on an inconsistent state.

\subsubsection{Synchronization} The last important property of a STM system is the way it synchronizes transactions. In order to validate
correctly the transaction needs to make sure the validation result does not depend on race conditions and is correct until the commit 
is completed. This means either concurrent transactions are delayed or their commit does not change the validity. In Haskell the first
approach is taken. When a transaction commits, the TVars in the writeSet are locked, thus other transactions that may conflict are not 
able to commit at the same time. In order to avoid a deadlock when two transaction try to lock mutual TVars\footnote{(e.g. transaction1 holding
tvar1 and tries to lock tvar2 and transaction2 holds tvar2 and tries to lock tvar1)}, all locks are released and the transaction
is rolled back if it tries to aquire the lock for a locked TVar. In the worst case this lead to the roll back of both transactions, 
however the chances are narrow. Rolling back the transaction seems to be harsh instead of waiting until the other transaction finishes 
and then trying to commit, but if two transactions try to lock the same TVar, both transactions try to write this TVar. 
This means at least one of the transactions is rolled back, since the writeSet is a subset of the readSet. 
Thus the first transaction to commit would modify a value in the readSet of the other transcation.

\section{Problems}
I will now explain two problems with this implementation. These problems can be examined independently. The first problem is about
\textit{when} a transaction is rolled back and the second problem is about \textit{how} a transaction is rolled back.

\subsection{Unnecessary Rollback}
\label{Prob:UnRo}
Remember the STM implementation of \code{transfer} and its example use given in \ref{STMInterface}: 
\par\noindent
\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}[frame=lrtb]
transaction1 = do
  atomically $
    transfer acc1 acc2 50
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}[frame=lrtb]
transcation2 = do 
  atomically $ 
    transfer acc2 acc1 50
\end{lstlisting}
\end{minipage}
The implmentation is correct, but not verry efficient in this case. Take a look at the inlined functions to understand the 
problem:
\par\noindent
\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}[frame=lrtb]
transaction1 = do
  a1 <- readTVar acc1
  a2 <- readTVar acc2
  writeTVar acc1 (a1 - 50)
  writeTVar acc2 (a2 + 50)
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}[frame=lrtb]
transaction2 = do 
  a1 <- readTVar acc2
  a2 <- readTVar acc1
  writeTVar acc2 (a1 - 50)
  writeTVar acc1 (a2 + 50)
\end{lstlisting}
\end{minipage}

Due to the scheduler the thread can run in a sequential order. This case may occur, but is not desirable. It means 
there is no performce improvement by executing this on a multiple cores/processors. Thus the efforts to use multiple
threads are futile in the first place. This is not a problem specific to STM, but to all synchronization mechanisms. 
If the resulting multi thread program is not scheduled in a way that it is executed parallel, these mechanisms are a
performance deterioration rather than a performance improvement. Since we cannot access the scheduler, we ignore 
this case. 

The second case is that these transactions are run parallel. This should be the better case, because the implementation
has a chance to improve the performance. Sadly this is not the case. To understand why, we need to take a close look at 
the execution. Let us assume both threads execute their computation phase parallel. This means both read the initial 
values of \code{acc1} and \code{acc2} and add these information to their readSet. Furthermore add both transactions 
entries for \code{acc1} and \code{acc2} to their writeSet. Then both transactions try to commit, thus try to lock 
the TVars. If \code{transaction1} gets the locks for \code{acc1} and \code{acc2} it validates and commits, since none of 
the TVars has changed after \code{transaction1} read them. After that \code{transaction2} aquires the locks and validates.
Since \code{transaction1} changed the version numbers of \code{acc1} and \code{acc2} by committing, the validation fails
and \code{transaction2} is restarted. 
In conclusion no performance improvement was achieved. Both threads are still executed 
on after another and not parallel as intended.

If we rearrange the operations of \code{transfer}, we are able to see how this can be improved. Note that we can rearrange the 
operations to a certain degree without changing the semantics of the resulting code due to the ACI properties. 
\begin{lstlisting}
transfer src dst am = do 
  srcBal <- readTVar src
  writeTVar src (srcBal - am)
  dstBal <- readTVar dst
  writeTVar dst (dstBal - am)
\end{lstlisting}
Transfer basically consists of two parts. Decreasing the balance of the source accound and increasing the 
balance of the destination account. The actual values of \code{src} and \code{dst} are not important for
these transactions. If we delay the evaluation of readTVar to the commit phase, we avoid the 
aforementioned \textbf{unnecessary} rollback, because no transaction would read a value, that is overwritten
by another transaction afterwards. 

If we refer to our example: 
\par\noindent
\begin{minipage}[t]{.45\textwidth}
Thread 1:
\begin{lstlisting}[frame=lrtb]
transaction1 = do
  a1 <- readTVar acc1
  a2 <- readTVar acc2
  writeTVar acc1 (a1 - 50)
  writeTVar acc2 (a2 + 50)
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
Thread 2:
\begin{lstlisting}[frame=lrtb]
transaction2 = do 
  a1 <- readTVar acc2
  a2 <- readTVar acc1
  writeTVar acc2 (a1 - 50)
  writeTVar acc1 (a2 + 50)
\end{lstlisting}
\end{minipage}

If we change the semantics of \code{readTVar} by delaying the evaluation, the following happens.
Both transactions will execute the computation phase simultaneously. This means for \code{transaction1} adding
\code{(acc1,(a1 - 50))} and \code{(acc2,(a2 + 50))} to their writeSet (this is analog for \code{transaction2}).
At the first glance this seems to be incorrect since the value of \code{a1} and \code{a2} are not yet present.
For Haskell this is quite common. Haskells is a non-strict language, which means passing unevaluated expressions
is normal. 

After the computation phase the commit phase follows. The first step is to lock the read TVars in order to 
perform the validation. Since both transactions used the same TVars, they will commit successively instead of
parallel. 

Assume \code{transaction1} gets the locks first and trys to validate\footnote{You could argue that 
evaluating \code{readTVar} operation is necessary before validating, but this would not change the validity of the 
transaction, since the TVars are locked and can not be modified by other transactions at that point.}. 
Since the readSet is empty the validation is unnecessary; the empty readSet is always valid. 
Before \code{transaction1} is able to commit its writeSet it needs
to evaluate \code{a1} and \code{a2}. By doing this the \code{readTVar} operations are evaluated. Hence the 
TVar and its version number is added to the readSet and the actual value is return. Since the readSet is already 
validated at this point it is superfluous.

After \code{transaction1} finished and released the locks, \code{transaction2} aquires these locks
and validates. The readSet of \code{transaction2} is also empty, thus the validation succeeds. Then \code{transaction2} 
evaluates the \code{readTVar} operations and commits its writeSet before releasing the locks.

Both transactions run parallel as far as possible and did not roll back. In Chapter \ref{Chapter2}
are the limitations of this idea presented and the challenges that arise when implementing it.
Furthermore are solutions to these challenges introduced.


\subsection{Unnecessary Recomputations}
While the first problem dealed with then question \textit{when} transactions should be rolled back,
the second problem investigates the question \textit{how} transactions are rolled back. Take a look
at the following example:
\begin{lstlisting}
transaction = do 
  a <- readTVar t1	
  writeTVar t1 (f a)	
  b <- readTVar t2	
  writeTVar t2 (g b)	
\end{lstlisting}
This transaction contains two independent statements. The first two lines of the transacton form the first 
statement. This is independent of the last two lines. Independent means their side effects or results do not 
influence each other. While the first line influces the second line, it does not influence the last two lines
and vice versa. 

If the transaction is now executed it computes its writeSet and readSet first. Then it locks the TVars and 
validates. The validation fails if either of the TVar has changed after it was read by the transaction.
If the validation fails the transcation is rolled back. Which means the readSet and writeSet are discarded,
regardless which TVar was the reason for the failed validation. 

For example if \code{t1} was modified after the transaction read it, the transaction is rolled back and both 
statements are executed again. This includes the read and write of \code{t2} although the value of 
\code{t2} did not change. Hence the exact same code with same inputs and the same (relevant) environment is 
executed twice. If we are able to invalidate parts of transactions instead of transactions as a whole, 
we can save time when rolling back a transaction.  
In the previous example we can use the information that only \code{t1} changed. If we roll back this 
transaction, we onky need to execute the first two actions, because the last two actions do not depend 
on \code{t1}.

% Some may argue it is not common to execute independent statements in a single transaction. However, I do not want  
% the performance of the STM library to rely on the capabilities of the programmer. 
% Furthermore do I not want to make any asssumption on how the library is most likely be used. 
% I am not sure if there
% are cases in which the execution of independent statements is needed, but I do not want the user to think 
% about this issue. The user should focus on the correctness of the code; the performance is the task of the
% library. 

% TODO: this technique may even be used for dependent statements aswell by reexecuting just tails of a dependence
% chain instead of the whole dependent chains

This concludes the overview on the problems of the current STM implementation. We will now turn over to the 
solution for this problems.







% This is the frist phase of a transaction execution. In this phase the reads and all pure calculations are performed. 
% Aforementioned IO action cannot be executed within a transaction, but pure computation may be executed like the following
% example demonstrates:
% \begin{lstlisting}
% transaction = do 
%   val <- readTVar t
%   if f val 
%     then writeTVar t (g val)
%     else retry
% 
% f v = some calculations...    
% g v = some other calculations...
% \end{lstlisting}
% Thus even if the calculation of \code{g} can be delayed thanks to laziness, the calculation of f has to be performed within that transaction.
% The results of \code{f} effects the control flow and thus needs to be evaluated to determine the result of the branch statement. 
% 
% Since 

